AUTONOMOUS DRONE NAVIGATION USING DYNAMIC ENVIRONMENT

Problem Statement:

Autonomous drones face challenges in navigating obstacle-filled environments while optimizing their paths efficiently. Traditional navigation methods require predefined paths, which may not be effective in dynamic scenarios. Reinforcement Learning (RL) enables drones to learn optimal navigation strategies through trial and error.


OBJECTIVE

•	Develop RL-based navigation for obstacle avoidance.
•	Train the drone using trial-and-error in a simulated environment.
•	To implement a reward-based learning system that encourages efficient and safe navigation.
•	To simulate various obstacle configurations and test the adaptability of the RL model.
•	To visualize the drone’s learning process and movement using 3D graphical tools.


METHODOLOGY

•	Create a 3D simulation.
•	Implement a DQN agent.
•	Train and evaluate the model.
•	Integrate a reward function that penalizes collisions and rewards goal achievement.
•	Apply experience replay to improve learning stability and efficiency.
•	Visualize drone movement dynamically using Plotly for better interpretation of learning behavior.


CONCLUSION

This project successfully demonstrates the use of Reinforcement Learning for autonomous drone navigation in obstacle-filled environments. By using a Deep Q-Network, the drone learns optimal paths through trial and error. The approach highlights the potential of RL in real-world applications like robotics and autonomous systems.

### ▶️ RL Output Video
[Watch the RL output video](assets/rl_output.mp4)








